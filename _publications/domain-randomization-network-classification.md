---
title: "Domain Randomization for Neural Network Classification"
collection: publications
permalink: /research/domain-randomization-network-classification
#excerpt: 'Large data requirements are often the main hurdle in training neural networks. Synthetic data is a cheap and efficient solution to assemble such large datasets. Using domain randomization, we show that a sufficiently well generated synthetic image dataset can be used to train a neural network classifier, achieving accuracy levels as high as 88% on 2 category classification. We show that the most important domain randomization parameter is a large variety of subjects, while secondary parameters such as lighting and textures are not. Based on our results, there is reason to believe that models trained on domain randomized images transfer to new domains better than those trained on real photos. Model performance seems to diminish slightly as the number of categories increases.'
date: 2020-10-01
venue: 'SpringerOpen Journal of Big Data'
paperurl: 'http://zarkonium.github.io/files/Domain_Randomization_for_Neural_Network_Classification_Published.pdf'
citation: 'Valtchev, SZ. and Wu, J. (2021). &quot;Domain Randomization for Neural Network Classification&quot;, <i>SpringerOpen Journal of Big Data</i>. 8:94.'
---
Large data requirements are often the main hurdle in training neural networks. Synthetic data is a cheap and efficient solution to assemble such large datasets. Using domain randomization, we show that a sufficiently well generated synthetic image dataset can be used to train a neural network classifier, achieving accuracy levels as high as 88% on 2 category classification. We show that the most important domain randomization parameter is a large variety of subjects, while secondary parameters such as lighting and textures are not. Based on our results, there is reason to believe that models trained on domain randomized images transfer to new domains better than those trained on real photos. Model performance seems to diminish slightly as the number of categories increases.
